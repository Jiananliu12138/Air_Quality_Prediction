{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bd8f9b3-b16d-4f6a-bebd-c58d91601fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local environment\n",
      "Added the following directory to the PYTHONPATH: F:\\ID2223\\Air_Quality_Prediction\n",
      "HopsworksSettings initialized!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def is_google_colab() -> bool:\n",
    "    if \"google.colab\" in str(get_ipython()):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clone_repository() -> None:\n",
    "    !git clone https://github.com/featurestorebook/mlfs-book.git\n",
    "    %cd mlfs-book\n",
    "\n",
    "def install_dependencies() -> None:\n",
    "    !pip install --upgrade uv\n",
    "    !uv pip install --all-extras --system --requirement pyproject.toml\n",
    "\n",
    "if is_google_colab():\n",
    "    clone_repository()\n",
    "    install_dependencies()\n",
    "    root_dir = str(Path().absolute())\n",
    "    print(\"Google Colab environment\")\n",
    "else:\n",
    "    root_dir = Path().absolute()\n",
    "    # Strip ~/notebooks/ccfraud from PYTHON_PATH if notebook started in one of these subdirectories\n",
    "    if root_dir.parts[-1:] == ('airquality',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    if root_dir.parts[-1:] == ('notebooks',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    root_dir = str(root_dir) \n",
    "    print(\"Local environment\")\n",
    "\n",
    "# Add the root directory to the `PYTHONPATH` to use the `recsys` Python module from the notebook.\n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "print(f\"Added the following directory to the PYTHONPATH: {root_dir}\")\n",
    "    \n",
    "# Set the environment variables from the file <root_dir>/.env\n",
    "from mlfs import config\n",
    "if os.path.exists(f\"{root_dir}/.env\"):\n",
    "    settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c7881d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <span style=\"font-width:bold; font-size: 3rem; color:#333;\">Vienna Multi-Sensor Training Pipeline</span>\n",
    "\n",
    "## üóíÔ∏è This notebook trains independent models for each Vienna sensor\n",
    "\n",
    "### Pipeline Overview:\n",
    "1. Load Vienna sensor configuration and feature groups\n",
    "2. **For each of the 9 active sensors:**\n",
    "   - Filter sensor-specific data\n",
    "   - Add lagged features (PM2.5 from 1, 2, 3 days ago)\n",
    "   - Create Feature View with weather + lagged features\n",
    "   - Train Enhanced XGBoost model\n",
    "   - Evaluate model performance (MSE, RMSE, MAE, R¬≤)\n",
    "   - Save model to Hopsworks Model Registry\n",
    "   - Generate visualizations (feature importance, predictions)\n",
    "3. Generate comprehensive training summary\n",
    "\n",
    "## üéØ Models Trained:\n",
    "This notebook will train **9 independent enhanced models**, one for each sensor:\n",
    "- Kendlerstra√üe 40\n",
    "- Hausgrundweg 23\n",
    "- AKH Ostringweg\n",
    "- Gaudenzdorfer G√ºrtel\n",
    "- Belgradplatz\n",
    "- Floridsdorf Gerichtsgasse\n",
    "- Taborstra√üe\n",
    "- Wehlistra√üe 366\n",
    "- Josef Redl Gasse\n",
    "\n",
    "Each model uses **weather features + 3-day lagged PM2.5 features**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a498f102",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbb7e97d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import hopsworks\n",
    "from mlfs.airquality import util\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610de819",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üì° Connect to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be0f8518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîê Connecting to Hopsworks...\n",
      "2025-11-15 00:35:50,262 INFO: Initializing external client\n",
      "2025-11-15 00:35:50,266 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-15 00:35:51,745 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1298582\n",
      "‚úÖ Connected to Hopsworks Feature Store\n",
      "\n",
      "üì° Loading Vienna sensors configuration...\n",
      "\n",
      "üìç City: Vienna, Austria\n",
      "üì° Total sensors: 14\n",
      "üì° Active sensors: 9\n",
      "\n",
      "üéØ Will train 9 independent models:\n",
      "  1. Kendlerstra√üe 40 (Umspannwerk) (Kendlerstrasse-40)\n",
      "  2. Hausgrundweg 23, Gstr. 254 (Hausgrundweg-23)\n",
      "  3. Allgemeines Krankenhaus, Ostringweg (AKH-Ostringweg)\n",
      "  4. Umspannwerk Gaudenzdorfer G√ºrtel (Gaudenzdorfer-Guertel)\n",
      "  5. Belgradplatz (S√ºdostecke), Gstr.Nr. 816 (Belgradplatz)\n",
      "  6. Floridsdorf, Gerichtsgasse 1a (Floridsdorf-Gerichtsgasse)\n",
      "  7. Ecke Taborstra√üe - Glockengasse (Taborstrasse)\n",
      "  8. Wehlistra√üe 366, Gstr.Nr.2157 (Wehlistrasse-366)\n",
      "  9. Schafbergbad, Josef Redl Gasse 2 (Josef-Redl-Gasse)\n"
     ]
    }
   ],
   "source": [
    "# Check if HOPSWORKS_API_KEY env variable is set or if it is set in ~/.env\n",
    "if settings.HOPSWORKS_API_KEY is not None:\n",
    "    api_key = settings.HOPSWORKS_API_KEY.get_secret_value()\n",
    "    os.environ['HOPSWORKS_API_KEY'] = api_key\n",
    "\n",
    "print(\"üîê Connecting to Hopsworks...\")\n",
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store() \n",
    "secrets = hopsworks.get_secrets_api()\n",
    "\n",
    "print(\"‚úÖ Connected to Hopsworks Feature Store\")\n",
    "\n",
    "# Load Vienna sensors configuration\n",
    "print(\"\\nüì° Loading Vienna sensors configuration...\")\n",
    "vienna_config_str = secrets.get_secret(\"VIENNA_SENSORS_CONFIG\").value\n",
    "vienna_config = json.loads(vienna_config_str)\n",
    "\n",
    "country = vienna_config['country']\n",
    "city = vienna_config['city']\n",
    "all_sensors = vienna_config['sensors']\n",
    "active_sensors = [s for s in all_sensors if s.get('status') == 'active']\n",
    "\n",
    "print(f\"\\nüìç City: {city}, {country}\")\n",
    "print(f\"üì° Total sensors: {len(all_sensors)}\")\n",
    "print(f\"üì° Active sensors: {len(active_sensors)}\")\n",
    "print(f\"\\nüéØ Will train {len(active_sensors)} independent models:\")\n",
    "for i, sensor in enumerate(active_sensors, 1):\n",
    "    print(f\"  {i}. {sensor['name']} ({sensor['street']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72daba1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Retrieving Vienna Feature Groups...\n",
      "‚úÖ Feature Group: air_quality_vienna (v1)\n",
      "   Primary key: ['country', 'city', 'street']\n",
      "‚úÖ Feature Group: weather_vienna (v1)\n",
      "   Primary key: ['city', 'street']\n"
     ]
    }
   ],
   "source": [
    "# Retrieve Vienna-specific feature groups\n",
    "print(\"\\nüîÑ Retrieving Vienna Feature Groups...\")\n",
    "\n",
    "air_quality_fg = fs.get_feature_group(\n",
    "    name='air_quality_vienna',\n",
    "    version=1,\n",
    ")\n",
    "weather_fg = fs.get_feature_group(\n",
    "    name='weather_vienna',\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Feature Group: {air_quality_fg.name} (v{air_quality_fg.version})\")\n",
    "print(f\"   Primary key: {air_quality_fg.primary_key}\")\n",
    "print(f\"‚úÖ Feature Group: {weather_fg.name} (v{weather_fg.version})\")\n",
    "print(f\"   Primary key: {weather_fg.primary_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beab0bf7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style=\"color:#ff5f27;\"> üìÅ Prepare Model Directories </span>\n",
    "\n",
    "Create directories for storing model artifacts and visualizations for each sensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f6af031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Base model directory created: F:\\ID2223\\Air_Quality_Prediction\\notebooks\\airquality\\vienna_models\n",
      "‚úÖ Base images directory created: F:\\ID2223\\Air_Quality_Prediction\\notebooks\\airquality\\vienna_models\\images\n"
     ]
    }
   ],
   "source": [
    "# Create base directory for all models\n",
    "base_model_dir = Path(f\"{root_dir}/notebooks/airquality/vienna_models\")\n",
    "base_images_dir = Path(f\"{root_dir}/notebooks/airquality/vienna_models/images\")\n",
    "\n",
    "base_model_dir.mkdir(parents=True, exist_ok=True)\n",
    "base_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"‚úÖ Base model directory created: {base_model_dir}\")\n",
    "print(f\"‚úÖ Base images directory created: {base_images_dir}\")\n",
    "\n",
    "# Initialize results tracking\n",
    "all_models_results = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52cefbe",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style=\"color:#ff5f27;\"> üîÑ Main Training Loop </span>\n",
    "\n",
    "This cell trains an independent enhanced model for each Vienna sensor.\n",
    "\n",
    "For each sensor:\n",
    "1. Filter sensor-specific data\n",
    "2. Add lagged features (PM2.5 from 1, 2, 3 days ago)  \n",
    "3. Join with weather data\n",
    "4. Create Feature View\n",
    "5. Train XGBoost model\n",
    "6. Evaluate performance\n",
    "7. Save model to Hopsworks\n",
    "8. Generate visualizations\n",
    "\n",
    "**This may take 10-20 minutes to complete all 9 models.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23139282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üöÄ STARTING MULTI-SENSOR TRAINING PIPELINE\n",
      "================================================================================\n",
      "\n",
      "Total sensors to process: 9\n",
      "Estimated time: 10-20 minutes\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üîÑ SENSOR 1/9: Kendlerstra√üe 40 (Umspannwerk)\n",
      "   Street ID: Kendlerstrasse-40\n",
      "================================================================================\n",
      "\n",
      "üìä Step 1/8: Reading air quality data for Kendlerstrasse-40...\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.48s) \n",
      "   Total rows in Feature Group: 27695\n",
      "   Rows for Kendlerstrasse-40: 4288\n",
      "   Date range: 2014-01-01 00:00:00+00:00 to 2025-11-14 00:00:00+00:00\n",
      "\n",
      "üìä Step 2/8: Adding lagged features (1, 2, 3 days ago)...\n",
      "Created feature: lag_1_pm25\n",
      "Created feature: lag_2_pm25\n",
      "Created feature: lag_3_pm25\n",
      "\n",
      "Lagged features summary:\n",
      "  - Initial rows: 4288\n",
      "  - Rows after dropping NaN: 4285\n",
      "  - Dropped rows: 3\n",
      "   Rows before: 4288\n",
      "   Rows after: 4285\n",
      "   Rows dropped (NaN in lags): 3\n",
      "   New columns: ['lag_1_pm25', 'lag_2_pm25', 'lag_3_pm25']\n",
      "\n",
      "üìä Step 3/8: Creating Feature Group with lagged features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 4285/4285 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: air_quality_with_lags_vienna_kendlerstrasse_40_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1298582/jobs/named/air_quality_with_lags_vienna_kendlerstrasse_40_1_offline_fg_materialization/executions\n",
      "2025-11-15 00:36:32,784 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-11-15 00:36:36,002 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n"
     ]
    }
   ],
   "source": [
    "# Main training loop: train one model for each sensor\n",
    "print(\"=\"*80)\n",
    "print(\"üöÄ STARTING MULTI-SENSOR TRAINING PIPELINE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal sensors to process: {len(active_sensors)}\")\n",
    "print(f\"Estimated time: 10-20 minutes\\n\")\n",
    "\n",
    "for sensor_idx, sensor in enumerate(active_sensors, 1):\n",
    "    sensor_name = sensor['name']\n",
    "    sensor_street = sensor['street']\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"üîÑ SENSOR {sensor_idx}/{len(active_sensors)}: {sensor_name}\")\n",
    "    print(f\"   Street ID: {sensor_street}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        # STEP 1: Read and filter sensor-specific air quality data\n",
    "        print(f\"\\nüìä Step 1/{8}: Reading air quality data for {sensor_street}...\")\n",
    "        air_quality_df_all = air_quality_fg.read()\n",
    "        air_quality_df_sensor = air_quality_df_all[air_quality_df_all['street'] == sensor_street].copy()\n",
    "        \n",
    "        print(f\"   Total rows in Feature Group: {len(air_quality_df_all)}\")\n",
    "        print(f\"   Rows for {sensor_street}: {len(air_quality_df_sensor)}\")\n",
    "        print(f\"   Date range: {air_quality_df_sensor['date'].min()} to {air_quality_df_sensor['date'].max()}\")\n",
    "        \n",
    "        if len(air_quality_df_sensor) < 10:\n",
    "            print(f\"   ‚ö†Ô∏è  Not enough data for {sensor_street}, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # STEP 2: Add lagged features\n",
    "        print(f\"\\nüìä Step 2/{8}: Adding lagged features (1, 2, 3 days ago)...\")\n",
    "        air_quality_df_with_lags = util.add_lagged_features(air_quality_df_sensor, lags=[1, 2, 3])\n",
    "        \n",
    "        rows_before = len(air_quality_df_sensor)\n",
    "        rows_after = len(air_quality_df_with_lags)\n",
    "        rows_dropped = rows_before - rows_after\n",
    "        \n",
    "        print(f\"   Rows before: {rows_before}\")\n",
    "        print(f\"   Rows after: {rows_after}\")\n",
    "        print(f\"   Rows dropped (NaN in lags): {rows_dropped}\")\n",
    "        print(f\"   New columns: {[col for col in air_quality_df_with_lags.columns if 'lag' in col]}\")\n",
    "        \n",
    "        # STEP 3: Create/update Feature Group with lagged features\n",
    "        print(f\"\\nüìä Step 3/{8}: Creating Feature Group with lagged features...\")\n",
    "        fg_name = f\"air_quality_with_lags_vienna_{sensor_street.replace('-', '_').lower()}\"\n",
    "        \n",
    "        air_quality_with_lags_fg = fs.get_or_create_feature_group(\n",
    "            name=fg_name,\n",
    "            description=f\"Air Quality with lagged PM2.5 features for Vienna sensor: {sensor_street}\",\n",
    "            version=1,\n",
    "            primary_key=['country', 'city', 'street'],\n",
    "            event_time=\"date\",\n",
    "            online_enabled=False,\n",
    "        )\n",
    "        \n",
    "        air_quality_with_lags_fg.insert(air_quality_df_with_lags, overwrite=True, wait=True, write_options={\"wait_for_job\": True})\n",
    "        print(f\"   ‚úÖ Feature Group '{fg_name}' - data inserted\")\n",
    "        \n",
    "        # CRITICAL: Wait for Feature Group to be fully queryable\n",
    "        print(f\"   ‚è∞ Waiting for indexing to complete...\")\n",
    "        import time\n",
    "        time.sleep(30)  # Wait 30 seconds for backend indexing\n",
    "        \n",
    "        # Verify Feature Group is readable\n",
    "        print(f\"   üîç Verifying Feature Group is queryable...\")\n",
    "        max_retries = 4\n",
    "        for retry in range(max_retries):\n",
    "            try:\n",
    "                test_df = air_quality_with_lags_fg.read(limit=1)\n",
    "                if len(test_df) > 0:\n",
    "                    print(f\"   ‚úÖ Feature Group is ready and queryable\")\n",
    "                    break\n",
    "                else:\n",
    "                    raise Exception(\"Feature Group returned empty data\")\n",
    "            except Exception as e:\n",
    "                if retry < max_retries - 1:\n",
    "                    print(f\"   ‚è∞ Retry {retry+1}/{max_retries} - waiting 20s...\")\n",
    "                    time.sleep(60)\n",
    "                else:\n",
    "                    print(f\"   ‚ùå Feature Group not queryable after {max_retries} retries\")\n",
    "                    raise e\n",
    "        \n",
    "        # STEP 4: Create Feature View (weather + lagged features)\n",
    "        print(f\"\\nüìä Step 4/{8}: Creating Feature View...\")\n",
    "        \n",
    "        # Select features for model (MUST include 'pm25' as it will be used as label)\n",
    "        selected_features_query = air_quality_with_lags_fg.select(['date', 'pm25', 'lag_1_pm25', 'lag_2_pm25', 'lag_3_pm25']) \\\n",
    "            .join(weather_fg.select(['temperature_2m_mean', 'precipitation_sum', 'wind_speed_10m_max', 'wind_direction_10m_dominant']),\n",
    "                  on=['city', 'street'])\n",
    "        \n",
    "        fv_name = f\"air_quality_fv_enhanced_{sensor_street.replace('-', '_').lower()}\"\n",
    "        \n",
    "        try:\n",
    "            fs.get_feature_view(name=fv_name, version=1).delete()\n",
    "            print(f\"   Deleted existing Feature View: {fv_name}\")\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        feature_view_enhanced = fs.create_feature_view(\n",
    "            name=fv_name,\n",
    "            description=f\"Enhanced air quality prediction features (weather + lags) for {sensor_street}\",\n",
    "            query=selected_features_query,\n",
    "            labels=['pm25']\n",
    "        )\n",
    "        \n",
    "        print(f\"   ‚úÖ Feature View '{fv_name}' created\")\n",
    "        \n",
    "        # STEP 5: Create training/test split\n",
    "        print(f\"\\nüìä Step 5/{8}: Creating training/test split...\")\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = feature_view_enhanced.train_test_split(\n",
    "            test_size=0.2,\n",
    "            description='Air quality training dataset (enhanced with lags)',\n",
    "        )\n",
    "        \n",
    "        # Drop 'date' column for training\n",
    "        X_train_features = X_train.drop(columns=['date'])\n",
    "        X_test_features = X_test.drop(columns=['date'])\n",
    "        \n",
    "        print(f\"   Training set: {len(X_train_features)} samples\")\n",
    "        print(f\"   Test set: {len(X_test_features)} samples\")\n",
    "        print(f\"   Features: {X_train_features.columns.tolist()}\")\n",
    "        \n",
    "        # STEP 6: Train Enhanced XGBoost model\n",
    "        print(f\"\\nüìä Step 6/{8}: Training Enhanced XGBoost model...\")\n",
    "        \n",
    "        model_enhanced = XGBRegressor(\n",
    "            n_estimators=100,\n",
    "            max_depth=5,\n",
    "            learning_rate=0.1,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        model_enhanced.fit(X_train_features, y_train)\n",
    "        print(f\"   ‚úÖ Model training completed\")\n",
    "        \n",
    "        # STEP 7: Evaluate model\n",
    "        print(f\"\\nüìä Step 7/{8}: Evaluating model performance...\")\n",
    "        \n",
    "        y_pred_train = model_enhanced.predict(X_train_features)\n",
    "        y_pred_test = model_enhanced.predict(X_test_features)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "        mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "        rmse_train = np.sqrt(mse_train)\n",
    "        rmse_test = np.sqrt(mse_test)\n",
    "        mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "        mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "        r2_train = r2_score(y_train, y_pred_train)\n",
    "        r2_test = r2_score(y_test, y_pred_test)\n",
    "        \n",
    "        print(f\"\\n   üìà Training Performance:\")\n",
    "        print(f\"      MSE:  {mse_train:.2f}\")\n",
    "        print(f\"      RMSE: {rmse_train:.2f}\")\n",
    "        print(f\"      MAE:  {mae_train:.2f}\")\n",
    "        print(f\"      R¬≤:   {r2_train:.4f}\")\n",
    "        \n",
    "        print(f\"\\n   üìà Test Performance:\")\n",
    "        print(f\"      MSE:  {mse_test:.2f}\")\n",
    "        print(f\"      RMSE: {rmse_test:.2f}\")\n",
    "        print(f\"      MAE:  {mae_test:.2f}\")\n",
    "        print(f\"      R¬≤:   {r2_test:.4f}\")\n",
    "        \n",
    "        # Store results\n",
    "        model_result = {\n",
    "            'sensor_name': sensor_name,\n",
    "            'sensor_street': sensor_street,\n",
    "            'train_samples': len(X_train_features),\n",
    "            'test_samples': len(X_test_features),\n",
    "            'mse_train': float(mse_train),\n",
    "            'mse_test': float(mse_test),\n",
    "            'rmse_train': float(rmse_train),\n",
    "            'rmse_test': float(rmse_test),\n",
    "            'mae_train': float(mae_train),\n",
    "            'mae_test': float(mae_test),\n",
    "            'r2_train': float(r2_train),\n",
    "            'r2_test': float(r2_test),\n",
    "        }\n",
    "        all_models_results.append(model_result)\n",
    "        \n",
    "        # STEP 8: Save model and generate visualizations\n",
    "        print(f\"\\nüìä Step 8/{8}: Saving model and generating visualizations...\")\n",
    "        \n",
    "        # Create sensor-specific directory\n",
    "        sensor_model_dir = base_model_dir / sensor_street.replace('-', '_').lower()\n",
    "        sensor_model_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Save model locally (XGBoost .json format)\n",
    "        model_path = str(sensor_model_dir / \"model.json\")\n",
    "        model_enhanced.save_model(model_path)\n",
    "        print(f\"   ‚úÖ Model saved to: {model_path}\")\n",
    "        \n",
    "        # Plot 1: Feature importance\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        plot_importance(model_enhanced, ax=ax, importance_type='weight', max_num_features=10)\n",
    "        plt.title(f'Feature Importance - {sensor_name}')\n",
    "        plt.tight_layout()\n",
    "        importance_path = base_images_dir / f\"feature_importance_{sensor_street.replace('-', '_').lower()}.png\"\n",
    "        plt.savefig(importance_path, dpi=100, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"   ‚úÖ Feature importance plot saved: {importance_path.name}\")\n",
    "        \n",
    "        # Plot 2: Predictions comparison\n",
    "        df_pred = pd.DataFrame({\n",
    "            'date': X_test['date'],\n",
    "            'actual': y_test.values,\n",
    "            'predicted': y_pred_test\n",
    "        }).sort_values('date')\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        ax.plot(df_pred['date'], df_pred['actual'], label='Actual PM2.5', marker='o', markersize=3, linewidth=1)\n",
    "        ax.plot(df_pred['date'], df_pred['predicted'], label='Predicted PM2.5', marker='x', markersize=3, linewidth=1)\n",
    "        ax.set_xlabel('Date')\n",
    "        ax.set_ylabel('PM2.5 (Œºg/m¬≥)')\n",
    "        ax.set_title(f'PM2.5 Predictions - {sensor_name}')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        pred_path = base_images_dir / f\"pm25_predictions_{sensor_street.replace('-', '_').lower()}.png\"\n",
    "        plt.savefig(pred_path, dpi=100, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"   ‚úÖ Predictions plot saved: {pred_path.name}\")\n",
    "        \n",
    "        # Save model to Hopsworks Model Registry\n",
    "        print(f\"\\n   üíæ Uploading model to Hopsworks Model Registry...\")\n",
    "        \n",
    "        mr = project.get_model_registry()\n",
    "        \n",
    "        metrics_dict = {\n",
    "            \"mse_train\": float(mse_train),\n",
    "            \"mse_test\": float(mse_test),\n",
    "            \"rmse_train\": float(rmse_train),\n",
    "            \"rmse_test\": float(rmse_test),\n",
    "            \"mae_train\": float(mae_train),\n",
    "            \"mae_test\": float(mae_test),\n",
    "            \"r2_train\": float(r2_train),\n",
    "            \"r2_test\": float(r2_test),\n",
    "            \"n_train_samples\": int(len(X_train_features)),\n",
    "            \"n_test_samples\": int(len(X_test_features)),\n",
    "        }\n",
    "        \n",
    "        model_name = f\"vienna_pm25_model_{sensor_street.replace('-', '_').lower()}\"\n",
    "        \n",
    "        aq_model = mr.python.create_model(\n",
    "            name=model_name,\n",
    "            description=f\"PM2.5 prediction model for Vienna sensor: {sensor_name} ({sensor_street}). Enhanced model with weather + lagged features.\",\n",
    "            metrics=metrics_dict,\n",
    "            model_schema={\n",
    "                \"input_schema\": {\n",
    "                    \"features\": X_train_features.columns.tolist()\n",
    "                },\n",
    "                \"output_schema\": {\n",
    "                    \"predictions\": [\"pm25\"]\n",
    "                }\n",
    "            },\n",
    "            feature_view=feature_view_enhanced,\n",
    "        )\n",
    "        \n",
    "        aq_model.save(str(sensor_model_dir))\n",
    "        print(f\"   ‚úÖ Model '{model_name}' uploaded to Hopsworks Model Registry\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ Completed sensor {sensor_idx}/{len(active_sensors)}: {sensor_name}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error processing sensor {sensor_name}: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        continue\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ MULTI-SENSOR TRAINING PIPELINE COMPLETED\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nSuccessfully trained {len(all_models_results)} models\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a531eb10",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style=\"color:#ff5f27;\"> üìä Training Summary </span>\n",
    "\n",
    "Generate comprehensive summary of all trained models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a79e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary DataFrame\n",
    "summary_df = pd.DataFrame(all_models_results)\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"üìä TRAINING SUMMARY - ALL SENSORS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(f\"\\nüéØ Total models trained: {len(summary_df)}\")\n",
    "print(f\"\\nüìà Performance Summary:\")\n",
    "\n",
    "# Display summary table\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "display(summary_df[['sensor_name', 'sensor_street', 'train_samples', 'test_samples', \n",
    "                     'rmse_test', 'mae_test', 'r2_test']])\n",
    "\n",
    "print(f\"\\nüìä Average Performance Across All Sensors:\")\n",
    "print(f\"   Average Test RMSE: {summary_df['rmse_test'].mean():.2f}\")\n",
    "print(f\"   Average Test MAE:  {summary_df['mae_test'].mean():.2f}\")\n",
    "print(f\"   Average Test R¬≤:   {summary_df['r2_test'].mean():.4f}\")\n",
    "\n",
    "print(f\"\\nüèÜ Best Performing Sensor (by Test R¬≤):\")\n",
    "best_sensor = summary_df.loc[summary_df['r2_test'].idxmax()]\n",
    "print(f\"   Sensor: {best_sensor['sensor_name']}\")\n",
    "print(f\"   Test R¬≤: {best_sensor['r2_test']:.4f}\")\n",
    "print(f\"   Test RMSE: {best_sensor['rmse_test']:.2f}\")\n",
    "\n",
    "print(f\"\\nüìâ Worst Performing Sensor (by Test R¬≤):\")\n",
    "worst_sensor = summary_df.loc[summary_df['r2_test'].idxmin()]\n",
    "print(f\"   Sensor: {worst_sensor['sensor_name']}\")\n",
    "print(f\"   Test R¬≤: {worst_sensor['r2_test']:.4f}\")\n",
    "print(f\"   Test RMSE: {worst_sensor['rmse_test']:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff196036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model performance comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Plot 1: Test RMSE comparison\n",
    "ax1 = axes[0, 0]\n",
    "summary_df_sorted = summary_df.sort_values('rmse_test')\n",
    "ax1.barh(summary_df_sorted['sensor_street'], summary_df_sorted['rmse_test'], color='steelblue')\n",
    "ax1.set_xlabel('Test RMSE')\n",
    "ax1.set_title('Model Performance Comparison (RMSE)')\n",
    "ax1.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Plot 2: Test R¬≤ comparison\n",
    "ax2 = axes[0, 1]\n",
    "summary_df_sorted = summary_df.sort_values('r2_test', ascending=False)\n",
    "ax2.barh(summary_df_sorted['sensor_street'], summary_df_sorted['r2_test'], color='forestgreen')\n",
    "ax2.set_xlabel('Test R¬≤')\n",
    "ax2.set_title('Model Performance Comparison (R¬≤)')\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Plot 3: Test MAE comparison\n",
    "ax3 = axes[1, 0]\n",
    "summary_df_sorted = summary_df.sort_values('mae_test')\n",
    "ax3.barh(summary_df_sorted['sensor_street'], summary_df_sorted['mae_test'], color='coral')\n",
    "ax3.set_xlabel('Test MAE')\n",
    "ax3.set_title('Model Performance Comparison (MAE)')\n",
    "ax3.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Plot 4: Training vs Test RMSE\n",
    "ax4 = axes[1, 1]\n",
    "x = range(len(summary_df))\n",
    "ax4.scatter(summary_df['rmse_train'], summary_df['rmse_test'], s=100, alpha=0.6, color='purple')\n",
    "ax4.plot([0, summary_df[['rmse_train', 'rmse_test']].max().max()],\n",
    "         [0, summary_df[['rmse_train', 'rmse_test']].max().max()],\n",
    "         'r--', alpha=0.5, label='Perfect fit line')\n",
    "ax4.set_xlabel('Training RMSE')\n",
    "ax4.set_ylabel('Test RMSE')\n",
    "ax4.set_title('Training vs Test RMSE')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# Add sensor labels to scatter plot\n",
    "for idx, row in summary_df.iterrows():\n",
    "    ax4.annotate(row['sensor_street'], \n",
    "                (row['rmse_train'], row['rmse_test']),\n",
    "                fontsize=8, alpha=0.7, \n",
    "                xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "plt.tight_layout()\n",
    "comparison_path = base_images_dir / \"models_performance_comparison.png\"\n",
    "plt.savefig(comparison_path, dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Performance comparison plot saved: {comparison_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5c1915",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style=\"color:#ff5f27;\"> üéâ Training Pipeline Complete! </span>\n",
    "\n",
    "### ‚úÖ Summary of Accomplishments:\n",
    "\n",
    "1. **Models Trained**: {len(all_models_results)} independent enhanced models\n",
    "2. **Feature Engineering**: Added 3-day lagged PM2.5 features for each sensor\n",
    "3. **Feature Groups Created**: One per sensor with lagged features\n",
    "4. **Feature Views Created**: One per sensor linking weather + lagged features\n",
    "5. **Models Saved**: \n",
    "   - Local storage in `vienna_models/` directory\n",
    "   - Hopsworks Model Registry\n",
    "6. **Visualizations Generated**:\n",
    "   - Feature importance plots (9 sensors)\n",
    "   - Prediction comparison plots (9 sensors)  \n",
    "   - Overall performance comparison plot\n",
    "\n",
    "### üìä Model Performance:\n",
    "- Average Test RMSE across all sensors\n",
    "- Each model uses weather features + 3-day lagged PM2.5\n",
    "- All models stored in Hopsworks Model Registry for deployment\n",
    "\n",
    "### üìÅ Artifacts Location:\n",
    "- **Models**: `{base_model_dir}/`\n",
    "- **Images**: `{base_images_dir}/`\n",
    "- **Summary**: `{base_model_dir}/training_summary.csv`\n",
    "\n",
    "### ‚è≠Ô∏è Next Steps:\n",
    "1. Run **batch inference pipeline** to generate predictions for all sensors\n",
    "2. Create **dashboard** to visualize predictions across Vienna\n",
    "3. Deploy models for **real-time predictions**\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "63265f9757e7c73c149a91832e3b2b12ced37a5390b9151ad08a04f276cd5846"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
